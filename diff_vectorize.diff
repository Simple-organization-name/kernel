diff -r --color kernel_working/kalloc.o build/kernel/kalloc.o
26,29c26,29
< 	subq	$72, %rsp
< 	.cfi_def_cfa_offset 128
< 	movb	%dil, 24(%rsp)
< 	movb	%sil, 16(%rsp)
---
> 	subq	$88, %rsp
> 	.cfi_def_cfa_offset 144
> 	movb	%dil, 20(%rsp)
> 	movb	%sil, 32(%rsp)
41c41
< 	addq	$72, %rsp
---
> 	addq	$88, %rsp
66c66
< 	movq	$32, (%rsp)
---
> 	movq	$32, 8(%rsp)
75d74
< 	movl	$2, %r13d
76a76
> 	movq	%rdx, 64(%rsp)
78a79
> 	movl	$2, %r13d
80c81
< 	movq	%rsi, 8(%rsp)
---
> 	movq	%rsi, 24(%rsp)
82,83c83,84
< 	movl	%r13d, %edi
< 	movq	%rdx, 48(%rsp)
---
> 	movl	%r13d, %esi
> 	movl	%eax, 76(%rsp)
85,87c86,87
< 	sall	%cl, %edi
< 	movl	%eax, 60(%rsp)
< 	movl	%edi, 28(%rsp)
---
> 	sall	%cl, %esi
> 	movl	%esi, 72(%rsp)
104c104
< 	cmpl	%ecx, %ebp
---
> 	cmpl	%ebp, %ecx
116c116
< 	movq	8(%rsp), %rax
---
> 	movq	24(%rsp), %rax
118c118
< 	movslq	28(%rsp), %rax
---
> 	movslq	72(%rsp), %rax
121c121
< 	cmpb	%r12b, 24(%rsp)
---
> 	cmpb	%r12b, 20(%rsp)
123,124c123,124
< 	movzbl	16(%rsp), %esi
< 	movzbl	24(%rsp), %edi
---
> 	movzbl	32(%rsp), %esi
> 	movzbl	20(%rsp), %edi
126,127c126,127
< 	movq	%r8, 32(%rsp)
< 	movq	48(%rsp), %rcx
---
> 	movq	%r8, 40(%rsp)
> 	movq	64(%rsp), %rcx
130c130
< 	movq	32(%rsp), %r8
---
> 	movq	40(%rsp), %r8
142c142
< 	movzbl	16(%rsp), %eax
---
> 	movzbl	32(%rsp), %eax
146c146
< 	cmpb	$0, 24(%rsp)
---
> 	cmpb	$0, 20(%rsp)
158c158
< 	cmpb	%r15b, 16(%rsp)
---
> 	cmpb	%r15b, 32(%rsp)
161c161
< 	movl	60(%rsp), %eax
---
> 	movl	76(%rsp), %eax
163c163
< 	movq	%rdx, (%rsp)
---
> 	movq	%rdx, 8(%rsp)
165c165
< 	movq	%r8, 16(%rsp)
---
> 	movq	%r8, 32(%rsp)
170c170
< 	movl	%eax, 24(%rsp)
---
> 	movl	%eax, 20(%rsp)
186c186
< 	cmpl	%ecx, %ebp
---
> 	cmpl	%ebp, %ecx
198,199c198,199
< 	movq	8(%rsp), %r9
< 	movl	24(%rsp), %edx
---
> 	movq	24(%rsp), %r9
> 	movl	20(%rsp), %esi
214c214
< 	movq	(%r9), %rcx
---
> 	movq	(%r9), %rdx
216,217c216,217
< 	shrq	$3, %rcx
< 	cmpb	$-1, (%rax,%rcx)
---
> 	shrq	$3, %rdx
> 	cmpb	$-1, (%rax,%rdx)
222c222
< 	xorl	%eax, %eax
---
> 	xorl	%edx, %edx
226,230c226,227
< 	movl	%edi, %esi
< 	sall	%cl, %esi
< 	movslq	%esi, %rsi
< 	addq	%rsi, %rax
< 	movl	%ecx, %esi
---
> 	movl	%edi, %eax
> 	sall	%cl, %eax
232c229,231
< 	cmpl	%ecx, %edx
---
> 	cltq
> 	addq	%rax, %rdx
> 	cmpl	%esi, %ecx
235,238d233
< 	movl	%r11d, %ecx
< 	leal	-6(%rsi), %edx
< 	addq	$8, %r9
< 	addq	%rax, %r15
239a235,237
> 	movl	%r11d, %ecx
> 	subl	$3, %esi
> 	addq	%rdx, %r15
240a239
> 	addq	$8, %r9
244a244
> 	movq	8(%rsp), %rax
246c246
< 	cmpq	%rbx, (%rsp)
---
> 	cmpq	%rax, %rbx
249c249
< 	movq	16(%rsp), %r8
---
> 	movq	32(%rsp), %r8
254c254
< 	movq	%r8, 32(%rsp)
---
> 	movq	%r8, 40(%rsp)
256,258c256,258
< 	movq	%r10, 40(%rsp)
< 	movl	%ebp, 56(%rsp)
< 	movq	%rdx, %rbp
---
> 	movq	%r10, 56(%rsp)
> 	movq	%rbx, 48(%rsp)
> 	movq	%rdx, %rbx
281c281
< 	divq	(%rsp)
---
> 	divq	8(%rsp)
297c297
< 	cmpq	%rdx, %rax
---
> 	cmpq	%rax, %rdx
318c318
< 	cmpq	%r9, %rbp
---
> 	cmpq	%rbx, %r9
321,325c321,325
< 	movq	%rbp, %rdx
< 	movq	32(%rsp), %r8
< 	movq	40(%rsp), %r10
< 	movl	56(%rsp), %ebp
< 	cmpb	%r15b, 16(%rsp)
---
> 	movq	%rbx, %rdx
> 	movq	40(%rsp), %r8
> 	movq	56(%rsp), %r10
> 	movq	48(%rsp), %rbx
> 	cmpb	%r15b, 32(%rsp)
353c353
< 	cmpq	%r9, %rbp
---
> 	cmpq	%r9, %rbx
370c370
< 	movq	%rcx, (%rsp)
---
> 	movq	%rcx, 8(%rsp)
386c386
< 	movq	8(%rsp), %r9
---
> 	movq	24(%rsp), %r9
389a390
> 	movl	$16, %esi
392d392
< 	movl	$16, %edx
395a396
> 	movq	8(%rsp), %rax
397c398
< 	cmpq	%rbx, (%rsp)
---
> 	cmpq	%rax, %rbx
447,448c448,450
< 	movq	24(%rax), %r8
< 	movzbl	%dil, %edx
---
> 	movq	24(%rax), %rdi
> 	movzbl	%r8b, %edx
> 	movq	8(%rax), %rax
450,451c452,453
< 	salq	$12, %r8
< 	testb	%dil, %dil
---
> 	salq	$12, %rdi
> 	testb	%r8b, %r8b
453,457c455,461
< 	leaq	-16(%rsi,%rdx), %r10
< 	movq	8(%r10), %r11
< 	movq	(%r10), %rbx
< 	addq	%r11, %rbx
< 	cmpq	8(%rax), %rbx
---
> 	leaq	-16(%rsi,%rdx), %r11
> 	movdqa	(%r11), %xmm1
> 	movdqa	%xmm1, %xmm0
> 	psrldq	$8, %xmm0
> 	paddq	%xmm1, %xmm0
> 	movq	%xmm0, %r10
> 	cmpq	%rax, %r10
460,464c464,468
< 	movq	8(%rax), %rax
< 	addq	%rsi, %rdx
< 	addl	$1, %edi
< 	movq	%r8, 8(%rdx)
< 	movq	%rax, (%rdx)
---
> 	movq	%rax, %xmm0
> 	movq	%rdi, %xmm2
> 	addl	$1, %r8d
> 	punpcklqdq	%xmm2, %xmm0
> 	movaps	%xmm0, 16(%rsp,%rdx)
468,469c472,473
< 	movzbl	%r9b, %r8d
< 	cmpq	%rax, %r8
---
> 	movzbl	%r9b, %edi
> 	cmpq	%rax, %rdi
474c478
< 	imulq	%r8, %rdx
---
> 	imulq	%rdi, %rdx
483,484c487,488
< 	movzbl	%r9b, %r8d
< 	cmpq	%rax, %r8
---
> 	movzbl	%r9b, %edi
> 	cmpq	%rax, %rdi
487c491
< 	testb	%dil, %dil
---
> 	testb	%r8b, %r8b
490c494
< 	movzbl	%dil, %r12d
---
> 	movzbl	%r8b, %r12d
504c508
< 	movq	(%rdx), %r11
---
> 	movq	(%rdx), %rdi
507,511c511,515
< 	leaq	2097151(%r11), %r8
< 	subq	%r11, %rax
< 	movq	%r8, %r9
< 	andq	$-2097152, %r9
< 	addq	%r9, %rax
---
> 	leaq	2097151(%rdi), %r9
> 	subq	%rdi, %rax
> 	movq	%r9, %r11
> 	andq	$-2097152, %r11
> 	addq	%r11, %rax
514c518
< 	cmpq	%r9, %r11
---
> 	cmpq	%r11, %rdi
516c520
< 	leal	-1(%rdi), %ebx
---
> 	leal	-1(%r8), %ebx
524c528
< 	movslq	%edx, %r11
---
> 	movslq	%edx, %rdi
527c531
< 	salq	$4, %r11
---
> 	salq	$4, %rdi
529,530c533
< 	movq	16(%rsp,%r11), %rbp
< 	movq	24(%rsp,%r11), %r11
---
> 	movdqa	(%rsi,%rdi), %xmm0
532,533c535
< 	movq	%r11, 24(%rsp,%rdx)
< 	movq	%rbp, 16(%rsp,%rdx)
---
> 	movaps	%xmm0, (%rsi,%rdx)
538,540c540,542
< 	movq	%rdx, %r11
< 	salq	$4, %r11
< 	movq	16(%rsp,%r11), %r11
---
> 	movq	%rdx, %rdi
> 	salq	$4, %rdi
> 	movq	16(%rsp,%rdi), %rdi
542c544
< 	movq	%r9, %rbx
---
> 	movq	%r11, %rbx
545c547
< 	subq	%r11, %rbx
---
> 	subq	%rdi, %rbx
555,557c557,559
< 	addq	$2097152, %r9
< 	andq	%rax, %r8
< 	movq	%r9, 16(%rsp,%rcx)
---
> 	addq	$2097152, %r11
> 	andq	%rax, %r9
> 	movq	%r11, 16(%rsp,%rcx)
560c562
< 	orq	%rax, %r8
---
> 	orq	%rax, %r9
562c564
< 	movq	%r8, -2101256
---
> 	movq	%r9, -2101256
570c572
< 	movzbl	%dil, %r11d
---
> 	movzbl	%r8b, %r11d
614c616
< 	cmpq	%rbx, %r11
---
> 	cmpq	%r11, %rbx
619,620c621,624
< 	addq	%r8, %r11
< 	movq	%r11, 8(%r10)
---
> 	movhlps	%xmm1, %xmm3
> 	movq	%xmm3, %rax
> 	addq	%rdi, %rax
> 	movq	%rax, 8(%r11)
816c820
< 	cmpl	%ecx, %esi
---
> 	cmpl	%esi, %ecx
993a998
> 	pxor	%xmm0, %xmm0
996d1000
< 	movl	$5, %edx
998,1003c1002,1005
< 	movq	$0, (%rsp)
< 	movq	$0, 8(%rsp)
< 	movq	$0, 16(%rsp)
< 	movq	$0, 24(%rsp)
< 	movq	$0, 32(%rsp)
< 	movq	$0, 40(%rsp)
---
> 	movl	$5, %edx
> 	movaps	%xmm0, (%rsp)
> 	movaps	%xmm0, 16(%rsp)
> 	movaps	%xmm0, 32(%rsp)
1018a1021
> 	pxor	%xmm0, %xmm0
1021d1023
< 	movl	$5, %edx
1023,1028c1025,1028
< 	movq	$0, (%rsp)
< 	movq	$0, 8(%rsp)
< 	movq	$0, 16(%rsp)
< 	movq	$0, 24(%rsp)
< 	movq	$0, 32(%rsp)
< 	movq	$0, 40(%rsp)
---
> 	movl	$5, %edx
> 	movaps	%xmm0, (%rsp)
> 	movaps	%xmm0, 16(%rsp)
> 	movaps	%xmm0, 32(%rsp)
diff -r --color kernel_working/kterm.o build/kernel/kterm.o
83c83
< 	movq	(%rdi), %rdx
---
> 	movq	(%rdi), %r9
85,86c85,86
< 	movq	(%rdx), %r11
< 	testb	%r8b, %r8b
---
> 	movq	(%r9), %r11
> 	testb	%dl, %dl
88,90c88,90
< 	movsd	.LC1(%rip), %xmm2
< 	movsd	.LC2(%rip), %xmm1
< 	movl	$12, %r9d
---
> 	movsd	.LC1(%rip), %xmm3
> 	movsd	.LC2(%rip), %xmm2
> 	movl	$12, %ecx
92a93
> 	movl	16(%r9), %eax
94,98c95,99
< 	pxor	%xmm0, %xmm0
< 	movl	16(%rdx), %eax
< 	movl	20(%rdx), %ecx
< 	cvtsi2sdl	%esi, %xmm0
< 	movl	24(%rdx), %edi
---
> 	xorl	%edx, %edx
> 	pxor	%xmm1, %xmm1
> 	cvtsi2sdl	%esi, %xmm1
> 	movl	20(%r9), %edi
> 	movd	24(%r9), %xmm0
100c101,102
< 	movl	%eax, 28+cursor(%rip)
---
> 	divl	%esi
> 	movd	16(%r9), %xmm6
102,107d103
< 	movw	%r10w, 20+cursor(%rip)
< 	mulsd	%xmm0, %xmm1
< 	movw	%r9w, 22+cursor(%rip)
< 	mulsd	%xmm2, %xmm0
< 	movl	%edi, 24+cursor(%rip)
< 	movl	%ecx, 32+cursor(%rip)
109,112c105,125
< 	cvttsd2sil	%xmm1, %edx
< 	movw	%dx, 16+cursor(%rip)
< 	cvttsd2sil	%xmm0, %edx
< 	movw	%dx, 18+cursor(%rip)
---
> 	mulsd	%xmm1, %xmm2
> 	movd	%edi, %xmm4
> 	punpckldq	%xmm6, %xmm0
> 	movzwl	%cx, %edx
> 	mulsd	%xmm3, %xmm1
> 	salq	$16, %rdx
> 	orq	%r10, %rdx
> 	salq	$16, %rdx
> 	cvttsd2sil	%xmm1, %r9d
> 	movzwl	%r9w, %ecx
> 	orq	%rcx, %rdx
> 	salq	$16, %rdx
> 	movd	%eax, %xmm5
> 	cvttsd2sil	%xmm2, %eax
> 	punpckldq	%xmm5, %xmm4
> 	punpcklqdq	%xmm4, %xmm0
> 	movups	%xmm0, 24+cursor(%rip)
> 	movzwl	%ax, %eax
> 	orq	%rax, %rdx
> 	movl	%edi, %eax
> 	movq	%rdx, 16+cursor(%rip)
115,118d127
< 	xorl	%edx, %edx
< 	movl	%eax, 36+cursor(%rip)
< 	movl	%ecx, %eax
< 	divl	%esi
125,127c134,136
< 	movsd	.LC0(%rip), %xmm2
< 	movsd	.LC1(%rip), %xmm1
< 	movl	$18, %r9d
---
> 	movsd	.LC0(%rip), %xmm3
> 	movsd	.LC1(%rip), %xmm2
> 	movl	$18, %ecx
